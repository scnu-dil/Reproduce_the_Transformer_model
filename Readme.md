通过阅读论文*Attention is all you need*来复现**Transformer**模型

# 已完成
- [x] 输入数据处理部分
- [x] transformer模型的训练部分
- [x] transformer模型的验证部分
- [x] transformer模型的推理部分
- [x] 输出数据生成部分

# 待完成
- [] 将当前代码拆分为各个模块
- [] 添加对模型训练部分，测试部分困惑度PPL和准确率ACC的图
- [] 优化模型代码，添加更多注释
- [] 构造输入参数约束函数
- [] 添加命令行参数模式
- [] 添加参考论文和代码的链接
